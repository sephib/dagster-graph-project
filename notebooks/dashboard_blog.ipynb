{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Pipeline Monitoring Dashboard\n",
    "\n",
    "These days any project that is deployed should incorporate the principles of CI/CD (highly recommend a [great talk from Eric Ma](https://www.youtube.com/watch?v=Dx2vG6qmtPs&t=232s) July 2020 - who describes the issue in the realm of _Data Science_ ).  \n",
    "After setting up our [dagster pipeline](https://dev.to/sephib/implementing-a-graph-network-pipeline-with-dagster-3i3a), we needed to implement some sort monitoring solution to review the outcome of our workflow. Working in a small DS team we had to push forward and couldn't wait for the _heavy guns_ of the enterprise IT to take over. So until we have their support, here is a simple dashboard that we have put together to monitor our `Assets`.\n",
    "\n",
    "In this blog post we describe how we have created a functional dashboard based on python widgets.  \n",
    "We describe the origin of our data, followed by our solution using python's [Panel](https://panel.holoviz.org/) library.  \n",
    "\n",
    "<img src=\"../docs/images/dashboard_plot.png\" alt=\"dashboard plot\" width=\"650\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dagster Assets   \n",
    "\n",
    "We are not going to dive into [Dagster](https://docs.dagster.io/) (see  previous [blog post on our data pipeline](https://dev.to/sephib/implementing-a-graph-network-pipeline-with-dagster-3i3a)), but the TLDR  is that Dagster is an orchestration framework for building modern data applications and workflows. The framework has integrated logging and the ability to [produce persistent assets](https://docs.dagster.io/overview/asset-materializations#materializing-an-asset) that are stored in a database (in our case _postgresql_) for future references.   \n",
    "For our project we are interested in monitoring the number of nodes and edges that we generate in our data pipline workflow. During our _pipeline run_ we log (or in the Dagster's jargon `Materialize` - see [AssetMaterialization in the documentation](https://docs.dagster.io/examples/materializations#main)) various stats on the datasets that we whish to  manipulate. We would like to view the changes of these stats over time in order to verify the \"health\" of our system/pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panel widgets  \n",
    "\n",
    "Today, the python ecosystem is very rich and vibrant with various visualization libraries that are constantly being developed. Two of the libraries that we reviewed were [streamlit](https://www.streamlit.io/) and [Panel](https://panel.holoviz.org/). We decided to go with Panel which seemed to suit our needs (due mainly to its structure and maintenance from our side).  \n",
    "Inspired by a talk given by  [Lina Weichbrodt in the MLOps meetup](https://www.youtube.com/watch?v=Un30yb1WlpU&feature=youtu.be),  we wanted to view the percent change of our metrics over time.   \n",
    "\n",
    "Panel is capable of displaying and integrating many python widgets from various packages. We are going to work with hvplot which best fits our needs, due to its richness and its integration with Pandas.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting our data/assets from the database\n",
    "In this section we describe how we extracted the data from `Dagster's Asset` database. If this is not relevant, you may want to jump to the sample data section below.  \n",
    "In order to access the `Asset` data we needed to dig into the `event_log` table which logs all the events that are generated when running a Dagster pipeline. The script to extracts the data into a Pandas Dataframe, based on the `Asset Keys` that are defined in the `Materialization` process, is in the [linked repo].    \n",
    "\n",
    "Here are the key elements in the script:  \n",
    "* In order to access the assets we need to query the `event_logs` table. We can use a `sqlalchemy` query as follows:  \n",
    "> select(\\[t_event_logs.c.event\\]).where(t_event_logs.c.asset_key.in_(assets))\n",
    "\n",
    "* For parsing the results we can use `dagster's` internal utility `deserialize_json_to_dagster_namedtuple`. Bellow is the function that converts the assets into a dictionary. Please note that we are only retrieving assets of a numeric type (which can be plotted). This is parallel to `dagit's` decision to display only asset numeric values in a graphs. \n",
    "\n",
    "```\n",
    "def get_asset_keys_values(results)->dict:\n",
    "    assets={}\n",
    "    for result in results:\n",
    "        dagster_namedtuple = deserialize_json_to_dagster_namedtuple(result[0])\n",
    "        time_stamp = datetime.fromtimestamp(dagster_namedtuple.timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        assets[time_stamp] = {}        \n",
    "        assets[time_stamp]['asset_key'] = dagster_namedtuple.dagster_event.asset_key.to_string()\n",
    "        from entry in dagster_namedtuple.dagster_event.event_specific_data.materialization.metadata_entries:\n",
    "            if isinstance(entry.entry_data, FloatMetadataEntryData):  # Only assets that are numerical\n",
    "                assets[time_stamp][entry.label] = entry.entry_data.value\n",
    "    return assets\n",
    "```\n",
    "\n",
    "\n",
    "The full code for retrieving the data is in [src/get_dagster_asset.py]() file. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Data \n",
    "\n",
    "For the dashboard in this post, we are going to use the sample data from bokeh.    \n",
    "\n",
    "Since we are simulating our datapipline outcomes we are going to use a sample of the columns:  \n",
    "* date - as our X / time axis\n",
    "* Temperature \t\n",
    "* Humidity \t\n",
    "* Light \n",
    "* CO2\n",
    "\n",
    "Let's view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>2015-02-04 10:40:59</td>\n",
       "      <td>24.330000</td>\n",
       "      <td>25.700000</td>\n",
       "      <td>817.0</td>\n",
       "      <td>1125.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>2015-02-04 10:41:59</td>\n",
       "      <td>24.356667</td>\n",
       "      <td>25.700000</td>\n",
       "      <td>813.0</td>\n",
       "      <td>1123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>2015-02-04 10:43:00</td>\n",
       "      <td>24.408333</td>\n",
       "      <td>25.681667</td>\n",
       "      <td>798.0</td>\n",
       "      <td>1124.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date  Temperature   Humidity  Light     CO2\n",
       "2802 2015-02-04 10:40:59    24.330000  25.700000  817.0  1125.8\n",
       "2803 2015-02-04 10:41:59    24.356667  25.700000  813.0  1123.0\n",
       "2804 2015-02-04 10:43:00    24.408333  25.681667  798.0  1124.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"../data/raw/panel-dashboard-dagster/datatest.txt\")\n",
    "data['date'] = data.date.astype('datetime64[ns]')\n",
    "cols = ['Temperature', 'Humidity', 'Light', 'CO2', ]\n",
    "data[['date'] + cols].tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested in the change of the various stats with time we can use Panda's [pct_change](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pct_change.html) method to generate the values that we need.  This also allows displaying all the datasets in the same graph since the nominal values of the various datasets are of different orders of magnitude.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>2015-02-04 10:40:59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001399</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>-0.003011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>2015-02-04 10:41:59</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004896</td>\n",
       "      <td>-0.002487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>2015-02-04 10:43:00</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>-0.000713</td>\n",
       "      <td>-0.018450</td>\n",
       "      <td>0.000890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date  Temperature  Humidity     Light       CO2\n",
       "2802 2015-02-04 10:40:59     0.000000 -0.001399  0.008891 -0.003011\n",
       "2803 2015-02-04 10:41:59     0.001096  0.000000 -0.004896 -0.002487\n",
       "2804 2015-02-04 10:43:00     0.002121 -0.000713 -0.018450  0.000890"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[cols] = data[cols].pct_change()\n",
    "data[['date'] + cols].tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data we can build our dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard  \n",
    "\n",
    "We have 2 widgets that we want to use in our dashboard:  \n",
    "1. A line plot -  displaying the datasets  \n",
    "1.1. A scatter plot - adding markers to the line plot \n",
    "3. A date_range_slider widget - presenting the date range that we want to display  \n",
    "\n",
    "\n",
    "Our dashboard will display each data series along the X time axis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DateRangeSlider\n",
    "\n",
    "Panel's [DateRangeSlider](https://panel.holoviz.org/reference/widgets/DateRangeSlider.html) widget \"allows selecting a date range using a slider with two handles\".  \n",
    "\n",
    "The parameters of the widget are self-explanitory   \n",
    "Please not that the `value` parameter is for the default values of the DateRangeSlider, which consists of the start..end of the slider.  \n",
    "\n",
    "```\n",
    "date_range_slider = pn.widgets.DateRangeSlider(\n",
    "        name='Date Range Slider',\n",
    "        start=data[date_col].min(), \n",
    "        end=data[date_col].max(),\n",
    "        value=(data[date_col].max() - timedelta(hours=1), \n",
    "               data[date_col].max()\n",
    "               )   # defualt value for slider\n",
    ")\n",
    "```  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Plot & Panel's Glue  \n",
    "\n",
    "Now let's look at the Line plot code:  \n",
    "\n",
    ">import holoviews.plotting.bokeh  \n",
    ">import hvplot.pandas  \n",
    "\n",
    "These define that [bokeh](https://bokeh.org/) will be the visualization engine for hvplot, in addition to allowing for hvplot to use directly Panda's dataframes as the datasources for the plots.  \n",
    "\n",
    "> @pn.depends(date_range_slider.param.value)  \n",
    "\n",
    "The Panel decorator causes the _line plot_ to vary - based on the value that is changed from the `date_range_slider` widget.   \n",
    "\n",
    "> start_date = date_range\\[0\\], end_date = date_range\\[1\\]  \n",
    "> mask = (crime_data\\[date_col\\] > start_date) & (crime_data\\[date_col\\] <= end_date)   \n",
    "> data = crime_data.loc\\[mask\\]   \n",
    "\n",
    "In order to filter the dataframe we are masking the data based on the current values from the `date_range_slider` widget.  \n",
    "\n",
    "> crime_data.hvplot.line  \n",
    "\n",
    "This is the basic call for a  [line plot] to be rendered from the Panda's dataframe.  \n",
    "\n",
    "\n",
    "The [scatter plot](https://hvplot.holoviz.org/reference/pandas/scatter.html) was added in order to display the value markers on the line plot\n",
    "\n",
    "\n",
    "Here is the full function:  \n",
    "```\n",
    "@pn.depends(date_range_slider.param.value)\n",
    "def get_plot(date_range):\n",
    "    data = dft\n",
    "    start_date = date_range[0]\n",
    "    end_date = date_range[1]\n",
    "    mask = (data[date_col] > start_date) & (data[date_col] <= end_date)\n",
    "    data = data.loc[mask]\n",
    "\n",
    "    lines = data[cols + [date_col]].hvplot.line(\n",
    "          x=date_col\n",
    "        , y=cols\n",
    "        , value_label= 'value'  \n",
    "        , legend='right'\n",
    "        , height=400\n",
    "        , width=800\n",
    "        , muted_alpha=0\n",
    "        , ylim=(-0.1, 0.1)  # This can be configured based on the pct change scale \n",
    "        , xlabel='time'\n",
    "        , ylabel='% change'\n",
    "    )   \n",
    "    scatter = data[cols + [date_col]].hvplot.scatter(\n",
    "                x=date_col,\n",
    "                y= cols,\n",
    "\n",
    "    )\n",
    "    return lines.opts(axiswise=True) * scatter\n",
    "```\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final function\n",
    "\n",
    "Now we can create a functions that connects the different widgets\n",
    "\n",
    "```\n",
    "def get_dashboard(dft, cols, date_col):\n",
    "    date_range_slider = pn.widgets.DateRangeSlider(\n",
    "        name='Date Range Slider',\n",
    "        start=data[date_col].min(), end=data[date_col].max(),\n",
    "        value=(data[date_col].max() - timedelta(hours=4), data[date_col].max(),)\n",
    "    )\n",
    "    @pn.depends(date_range_slider.param.value)\n",
    "    def get_plot(date_range):\n",
    "        data = dft\n",
    "        start_date = date_range[0]\n",
    "        end_date = date_range[1]\n",
    "        mask = (data[date_col] > start_date) & (data[date_col] <= end_date)\n",
    "        data = data.loc[mask]\n",
    "\n",
    "        lines = data[cols + [date_col]].hvplot.line(\n",
    "              x=date_col\n",
    "            , y=cols\n",
    "            , value_label= 'value'  \n",
    "            , legend='bottom_right'\n",
    "            , height=400\n",
    "            , width=800\n",
    "            , muted_alpha=0\n",
    "            , ylim=(-0.1, 0.1)  # This can be configured based on the pct change scale \n",
    "            , xlabel='time'\n",
    "            , ylabel='% change'\n",
    "        )   \n",
    "        scatter = data[cols + [date_col]].hvplot.scatter(\n",
    "                    x=date_col,\n",
    "                    y= cols,\n",
    "                    \n",
    "        )\n",
    "        return lines.opts(axiswise=True) * scatter\n",
    "    return get_plot, date_range_slider\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desgin the Dashboard  \n",
    "\n",
    "Panel has a simple method to aggregating all the widgets together using rows and columns (like a simple HTML table).   \n",
    "\n",
    "<img src=\"../docs/images/panel_layout.png\" alt=\"panel layout\" width=\"450\">  \n",
    "     \n",
    "Below is the code to design the layout  \n",
    "\n",
    "```\n",
    "plot, date_range_slider = get_dashboard(data, cols, 'date')\n",
    "dashboard=pn.Row(\n",
    "    pn.Column(\n",
    "        pn.pane.Markdown(''' ## Dataset Percent Change'''),\n",
    "        plot,\n",
    "        date_range_slider,\n",
    "        \n",
    "#         pn.widgets.DataFrame(data.set_index('date'), )\n",
    "    ),\n",
    "  \n",
    ")\n",
    "dashboard\n",
    "\n",
    "```  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion  \n",
    "In this blog post we have outlined our solution for monitoring our Dagster's Assets that we log during our data pipeline workflow.   \n",
    "Using the Panel / hvplot libraries was quite straightforward. The documentation and reference galleries were very useful, although getting the linkage between the plot and the checkbox is not optimal since the current solution does not rerender the plot, so it's convenient if the datasets are of the same order of magnitude. However if they aren't, this solution should be upgraded to be rerendered as the example as in the last section in the [getting started documentation](https://panel.holoviz.org/getting_started/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}